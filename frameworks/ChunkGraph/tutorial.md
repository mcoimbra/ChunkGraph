# ChunkGraph

This respository is for following paper:

**ATC'24 paper:** Efficient Large Graph Processing with Chunk-Based Graph Representation Model

## Abstract

Existing external graph processing systems face challenges
in terms of low I/O efficiency, expensive computation overhead,
and high development costs when running on emerging
NVMe SSDs. Due to their reliance on complex loading and
computing models that aim to convert numerous random I/Os
into a few sequential I/Os. While in-memory graph systems
working with memory-storage cache systems like OS page
cache or TriCache, offer a promising solution for large graph
processing with fine-grained I/Os and easy algorithm programming,
they often overlook the specific characteristics of
the graph, resulting in inefficient graph processing. To address
these challenges, we introduce ChunkGraph, an I/O-efficient
graph system designed for processing large-scale graphs on
NVMe SSDs. ChunkGraph introduces a novel chunk-based
graph representation model, featuring classified and hierarchical
vertex storage and efficient chunk layout optimization.
Evaluations show that ChunkGraph can outperform existing
external graph systems, as well as in-memory graph systems
relying on general cache systems, running several times faster.

## Try out ChunkGraph

### Compilers
* g++ >= 5.3.0 with OpenMP.

### Compiling 

Using the following commands, one can easily compile the `ChunkGraph`. 
Different graph processing algorithms can be compiled by the `Makefile` in the `apps` directory.

```bash
## Get source code
$ git clone 
$ cd ChunkGraph

## Make executable file for different graph processing algorithms
$ cd apps
$ export CHUNK=1
$ make
```

### Running

**Arguments setup:**
You can set up the arguments by using following command-line options.

```bash
./apps/[algo] [OPTION] [DATASET_PATH]
./exe options.
 -chunk: indicates input a chunk graph.
 -s: indicates input a symmetric graph.
 -c: indicates input a compressed graph.
 -b: indicates input a binary graph.
 -t: specifies the number of threads.
 -rounds: specifies the number of rounds for the algorithm.
 -buffer: specifies the buffer size for ChunkGraph.
 -threshold: specifies the threshold used by top-down/bottom-up selection.
```
**Example1: Run BFS algorithm in Twitter dataset by ChunkGraph.**

```bash
$ cd ChunkGraph/apps
$ ./BFS -b -r 12 -chunk -t 16 /Dataset/Twitter/twitter
```

The key statistic data for graph querying would be recorded to `chunkgraph_query_time.csv` file, e.g.
```bash
#[algo],[dataset_path],query_time
[./BFS],[/Dataset/Friendster/friendster@buffer:0],2.85
```


### Dataset preparing

ChunkGraph provides interfaces to ingest graph data from chunk-format files of binary format. 
Typically, the downloaded datasets are edge list files of text format. 
Additionally, as our comparison systems require the input data in csr-format files of binary format, we provide a script to convert the input data from text format to csr-based binary. 
For convenience, we provide a script to convert the input data from text format to csr-based binary and 
chunk-format binary. 


**Example1: LiveJournal (small graph for function test):**
```bash
# Download dataset and unzip
$ export ChunkGraph=$PWD
$ mkdir Dataset && cd Dataset
$ mkdir LiveJournal && cd LiveJournal
$ mkdir txt && cd txt
$ wget https://snap.stanford.edu/data/soc-LiveJournal1.txt.gz
$ gunzip soc-LiveJournal1.txt.gz
$ mv soc-LiveJournal1.txt livejournal.txt

## convert to csr format
$ cd $ChunkGraph
$ bash ./preprocess/text2csr.sh ./Dataset/LiveJournal/ livejournal
## convert to chunk format
$ mkdir ./Dataset/LiveJournal/chunk
$ bash ./preprocess/csr2chunk.sh ./Dataset/LiveJournal/csr_bin/ livejournal ./Dataset/LiveJournal/chunk/
```

**Example2: Friendster (Medium graph, one of our evaluation tested dataset):**
```bash
## Download and unzip
$ export ChunkGraph=$PWD
$ mkdir Dataset && cd Dataset
$ mkdir Friendster && cd Friendster
$ mkdir txt && cd txt
$ wget http://konect.cc/files/download.tsv.friendster.tar.bz2 
$ tar -jxvf friendster.tar.bz2
$ mv out.friendster friendster.txt

## convert to csr format
$ cd $ChunkGraph
$ bash ./preprocess/text2csr.sh ./Dataset/Friendster/ friendster
## convert to chunk format
$ mkdir ./Dataset/Friendster/chunk
$ bash ./preprocess/csr2chunk.sh ./Dataset/Friendster/csr_bin/ friendster ./Dataset/Friendster/chunk/
```

**Example3: Kron30 (Largest synthetic graph generated by graph500 generator):**
```bash
## Build graph500 
## A valid MPI-3 library is required to compile this project
$ git clone https://github.com/rwang067/graph500-3.0
$ cd graph500-3.0/src
$ make graph500_reference_bfs 

## Generate Kron30
$ export ChunkGraph=$PWD
$ mkdir Dataset && cd Dataset
$ mkdir Kron30 && mkdir Kron30/txt
$ ./graph500_reference_bfs 30 16 Kron30/txt/kron30.txt

## convert to csr format
$ cd $ChunkGraph
$ bash ./preprocess/text2csr.sh ./Dataset/Kron30/ kron30
## convert to chunk format
$ mkdir ./Dataset/Kron30/chunk
$ bash ./preprocess/csr2chunk.sh ./Dataset/Kron30/csr_bin/ kron30 ./Dataset/Kron30/chunk/
```

## Comparison Systems

### Ligra-mmap

We provide the mmap version of Ligra for comparison. 
Ligra-mmap ingests graph data from csr-format files of binary format. 
Compile and run the Ligra-mmap by the following commands.

```bash
# compile Ligra-mmap
$ cd apps && make
# run BFS on Twitter dataset
$ ./BFS -b -r 12 /Dataset/Twitter/twitter
```

### Blaze

Blaze is a graph processing system designed for SSDs. 
We use the Blaze system for comparison. 
Blaze ingests graph data from customized csr-format files of binary format. 
You can refer the README.md in the Blaze repository for more details.
Compile and run the Blaze by the following commands.

```bash
$ cd blaze
# compile Blaze
$ mkdir -p build && cd build && cmake .. && make -j
# run BFS on Twitter dataset
$ ./bin/bfs -computeWorkers 16 -startNode 12 /datapath/to/blaze/twitter/twitter.gr.index /datapath/to/blaze/twitter/twitter.gr.adj.0
# run BC on Twitter dataset
$ ./bin/bc -computeWorkers 16 -startNode 12 /datapath/to/blaze/twitter/twitter.gr.index /datapath/to/blaze/twitter/twitter.gr.adj.0 -inIndexFilename /datapath/to/blaze/twitter/twitter.tgr.index -inAdjFilenames /datapath/to/blaze/twitter/twitter.tgr.adj.0
```